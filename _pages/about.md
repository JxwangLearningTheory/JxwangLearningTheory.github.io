---
permalink: / 
author_profile: true

---

**Publications:**

1. <font color ="black"> Jinshan Zeng, Min Zhang and Shao-Bo Lin,</font><font size=3 color ="blue"> Fully corrective gradient boosting with squared hinge: Fast learning rates and early stopping, </font> <font color ="red"> Neural Networksï¼Œ2021.</font>

   [Google Scholar Page](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dGt4l6QAAAAJ&sortby=pubdate&citation_for_view=dGt4l6QAAAAJ:0ngZmJvimKcC) | ([Download PDF Here !](https://jxwanglearningtheory.github.io/files/2021_Fully-Corrective_Gradient.pdf)  )
 
2. <font color ="black">Han Feng, Shao-Bo Lin, Ding-Xuan Zhou, </font><font size=3 color ="blue">Radial Basis Function Approximation with Distributively Stored Data on Spheres,  </font> <font color ="red">arXiv preprint arXiv:2112.02499,2021.</font> 

   [Google Scholar Page](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dGt4l6QAAAAJ&sortby=pubdate&citation_for_view=dGt4l6QAAAAJ:7VEv-pLvLSsC) | ([Download PDF Here !](https://jxwanglearningtheory.github.io/files/2021_Radial_Basis_Function_Approximation.pdf)  )
 
 
3. <font color ="black">Han Feng, Shao-Bo Lin, Ding-Xuan Zhou, </font><font size=3 color ="blue">Generalization Performance of Empirical Risk Minimization on Over-parameterized Deep ReLU Nets,  </font> <font color ="red">arXiv preprint arXiv:2111.14039, 2021. </font> 

   [Google Scholar Page](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dGt4l6QAAAAJ&sortby=pubdate&citation_for_view=dGt4l6QAAAAJ:7VEv-pLvLSsC) | ([Download PDF Here !](https://jxwanglearningtheory.github.io/files/2021_GENERALIZATION_PERFORMANCE.pdf)  )
 
4. <font color ="black"> Zirui Sun, Mingwei Dai, Yao Wang, Shao-Bo Lin,</font><font size=3 color ="blue">Nystr\"{o} m Regularization for Time Series Forecasting,  </font> <font color ="red"> arXiv preprint arXiv:2111.07109, 2021.</font> 

   [Google Scholar Page](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dGt4l6QAAAAJ&sortby=pubdate&citation_for_view=dGt4l6QAAAAJ:j5aT6aphRxQC) | ([Download PDF Here !](https://jxwanglearningtheory.github.io/files/2021_Nystrom_Regularization.pdf)  )

5. <font color ="black"> Shao-Bo Lin, Kaidong Wang, Yao Wang, Ding-Xuan Zhou,</font><font size=3 color ="blue"> Universal Consistency of Deep Convolutional Neural Networks,</font> <font color ="red">arXiv preprint arXiv:2106.12498, 2021.</font> 

   [Google Scholar Page](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dGt4l6QAAAAJ&sortby=pubdate&citation_for_view=dGt4l6QAAAAJ:EBV337fEn3EC) | ([Download PDF Here !](https://jxwanglearningtheory.github.io/files/2021_Universal_Consistency.pdf)  )
 
 
6. <font color ="black">Jinshan Zeng, Shao-Bo Lin, Yuan Yao, Ding-Xuan Zhou, </font><font size=3 color ="blue"> On ADMM in deep learning: Convergence and saturation-avoidance, </font> <font color ="red">Journal of Machine Learning Research, 2021.</font> 

   [Google Scholar Page](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dGt4l6QAAAAJ&sortby=pubdate&citation_for_view=dGt4l6QAAAAJ:yIeBiWEAh44C) | ([Download PDF Here !](https://jxwanglearningtheory.github.io/files/2021_On_ADMM_in_Deep_Learning.pdf)  )
 
 
 
7. <font color ="black"> Shao-Bo Lin, Yu Guang Wang, Ding-Xuan Zhou,</font><font size=3 color ="blue">  Distributed filtered hyperinterpolation for noisy data on the sphere,</font> <font color ="red">SIAM Journal on Numerical Analysis, 2021.</font> 

   [Google Scholar Page](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dGt4l6QAAAAJ&sortby=pubdate&citation_for_view=dGt4l6QAAAAJ:Vztgr1qGG8IC) | ([Download PDF Here !](https://jxwanglearningtheory.github.io/files/2021_DISTRIBUTED_FILTERED_HYPERINTERPOLATION.pdf)  )
 

